{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13879561,"sourceType":"datasetVersion","datasetId":8842878},{"sourceId":13879935,"sourceType":"datasetVersion","datasetId":8843112},{"sourceId":13912823,"sourceType":"datasetVersion","datasetId":8864990},{"sourceId":13913555,"sourceType":"datasetVersion","datasetId":8865490},{"sourceId":14087637,"sourceType":"datasetVersion","datasetId":8969710}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation","metadata":{}},{"cell_type":"code","source":"# !pip cache purge\n# !rm -rf ~/.cache/pip\n# !rm -rf ~/.cache/*\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:28:37.893587Z","iopub.execute_input":"2025-12-10T11:28:37.893848Z","iopub.status.idle":"2025-12-10T11:28:37.897792Z","shell.execute_reply.started":"2025-12-10T11:28:37.893829Z","shell.execute_reply":"2025-12-10T11:28:37.897215Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -r /kaggle/input/new1-requirements/requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport io\nimport re\nimport uuid\nimport json\nimport tempfile\n\nfrom fastapi import FastAPI, UploadFile, File, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom starlette.responses import JSONResponse\n\nimport pdfplumber\nimport pytesseract\nimport docx2txt\nimport re\nfrom PIL import Image\n\nimport cv2\nfrom deepface import DeepFace\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport cv2\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:28:42.175548Z","iopub.execute_input":"2025-12-10T11:28:42.175809Z","iopub.status.idle":"2025-12-10T11:28:51.766899Z","shell.execute_reply.started":"2025-12-10T11:28:42.175785Z","shell.execute_reply":"2025-12-10T11:28:51.766321Z"}},"outputs":[{"name":"stderr","text":"2025-12-10 11:28:43.508119: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-12-10 11:28:43.508174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-10 11:28:43.509671: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:28:51.767585Z","iopub.execute_input":"2025-12-10T11:28:51.768125Z","iopub.status.idle":"2025-12-10T11:28:51.939731Z","shell.execute_reply.started":"2025-12-10T11:28:51.768095Z","shell.execute_reply":"2025-12-10T11:28:51.938967Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"markdown","source":"## load_file","metadata":{}},{"cell_type":"code","source":"def load_file(path):\n    ext = os.path.splitext(path)[1].lower()\n    if ext==\".pdf\":\n        text=\"\"\n        with pdfplumber.open(path) as pdf:\n            for p in pdf.pages:\n                t = p.extract_text()\n                if t: text+=t+\"\\n\"\n        if text.strip():\n            return text\n    \n        ocr=\"\"\n        with pdfplumber.open(path) as pdf:\n            for p in pdf.pages:\n                img=p.to_image(resolution=300).original\n                ocr+=pytesseract.image_to_string(img)\n        return ocr\n    if ext==\".docx\":\n        return docx2txt.process(path) or \"\"\n    if ext==\".txt\":\n        return open(path,\"r\",encoding=\"utf-8\", errors=\"ignore\").read()\n    if ext in [\".jpg\",\".jpeg\",\".png\"]:\n        return pytesseract.image_to_string(Image.open(path))\n    return \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:28:51.940571Z","iopub.execute_input":"2025-12-10T11:28:51.940827Z","iopub.status.idle":"2025-12-10T11:28:51.946632Z","shell.execute_reply.started":"2025-12-10T11:28:51.940804Z","shell.execute_reply":"2025-12-10T11:28:51.946007Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nmodel_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    cache_dir=\"/kaggle/temp_model\",\n    trust_remote_code=True\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    cache_dir=\"/kaggle/temp_model\",\n    device_map=\"auto\",         \n    torch_dtype=torch.float16, \n    \n    trust_remote_code=True,\n    repetition_penalty=1.15     )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:28:51.947417Z","iopub.execute_input":"2025-12-10T11:28:51.947677Z","iopub.status.idle":"2025-12-10T11:29:17.767056Z","shell.execute_reply.started":"2025-12-10T11:28:51.947654Z","shell.execute_reply":"2025-12-10T11:29:17.766470Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0934534835f042188138bd06855dd492"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## analyze_cv","metadata":{}},{"cell_type":"code","source":"def analyze_cv(cv_text, jd_text):\n    prompt = f\"\"\"\nYou are an expert recruiter.\n\nCV:\n{cv_text}\n\nJob Description:\n{jd_text}\n\nInstructions:\n1. Identify all skills required in the Job Description.\n2. Identify all skills mentioned in the CV.\n3. Extract the **matched skills** (skills present in both CV and JD, considering understanding, synonyms, and related concepts).\n4. Extract the **non-matched skills** (skills required in JD but not present in CV).\n5. Calculate **CV Score** = (number of matched skills / total skills in JD) * 100, rounded to 1 decimal.\n\nReturn ONLY in this format:\n\nMatched Skills\n- skill1\n- skill2\n...\n\nNon-Matched Skills\n- skill1\n- skill2\n...\n\nCV Score\nXX.X% match\n\nRules:\n- Do not repeat any skills.\n- Do not use placeholders.\n- Do not explain, comment, or acknowledge instructions.\n- Focus on actual content from CV and JD.\n\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=1024,\n        temperature=0.0,  \n        do_sample=False,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    if \"Matched Skills\" in full_output:\n        result = full_output[full_output.index(\"Matched Skills\"):].strip()\n    else:\n        result = full_output.strip()\n\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:44:34.146776Z","iopub.execute_input":"2025-12-10T11:44:34.147099Z","iopub.status.idle":"2025-12-10T11:44:34.152720Z","shell.execute_reply.started":"2025-12-10T11:44:34.147075Z","shell.execute_reply":"2025-12-10T11:44:34.151928Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## extract_cv score&skills","metadata":{}},{"cell_type":"code","source":"path=\"/kaggle/input/cv-version3/Nagwa Mohamed - AI - Machine Learning Engineer-1.pdf\"\njd=\"\"\"\n\nWe are looking for a Generative AI Engineer to join our research and development team.\nResponsibilities:\n- Design and fine-tune large language models (LLMs) using frameworks such as HuggingFace Transformers.\n- Build and deploy generative AI applications for text, image, and multimodal tasks.\n- Implement training pipelines with PyTorch or TensorFlow, and optimize models for performance.\n- Work with cloud platforms (AWS, Azure, GCP) to scale model training and deployment.\n- Apply MLOps practices using Docker, Kubernetes, MLflow, and Airflow.\n- Collaborate with data scientists to integrate generative models into production systems.\n- Research and experiment with diffusion models, GANs, and reinforcement learning for generative tasks.\n\nRequirements:\n- Strong programming skills in Python.\n- Experience with deep learning architectures (CNNs, RNNs, Transformers).\n- Knowledge of NLP techniques and computer vision.\n- Familiarity with CI/CD pipelines and GitHub Actions.\n- Bonus skills: LangChain, RAG (Retrieval-Augmented Generation), Vector Databases (FAISS, Pinecone, Weaviate), Databricks.\n\n\n\"\"\"\n# cv_text=load_file(path)\n# cv=analyze_cv(cv_text, jd)\n# print(cv)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_cv_score(result_text):\n    match = re.search(r\"CV Score\\s*([\\d]+(?:\\.\\d+)?)%\\s*match\", result_text, re.IGNORECASE)\n    if match:\n        return float(match.group(1))\n    return None\ndef extract_skills(result_text):\n    matched = []\n    missing = []\n\n    lines = result_text.splitlines()\n    mode = None\n\n    for line in lines:\n        line = line.strip()\n\n        if line.lower() == \"matched skills\":\n            mode = \"matched\"\n            continue\n        elif line.lower() == \"missing skills\":\n            mode = \"missing\"\n            continue\n        elif line.lower().startswith(\"cv score\"):\n            mode = None\n            continue\n\n        if mode == \"matched\" and line.startswith(\"-\"):\n            matched.append(line[1:].strip())\n\n        elif mode == \"missing\" and line.startswith(\"-\"):\n            missing.append(line[1:].strip())\n\n    return matched, missing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:46:09.779349Z","iopub.execute_input":"2025-12-10T11:46:09.779646Z","iopub.status.idle":"2025-12-10T11:46:09.786163Z","shell.execute_reply.started":"2025-12-10T11:46:09.779625Z","shell.execute_reply":"2025-12-10T11:46:09.785444Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# skill_matched, skill_missing = extract_skills(cv)\n# score = extract_cv_score(cv)\n\n# print(\"Matched Skills\")\n# for s in skill_matched:\n#     print(f\"- {s}\")\n\n# print(\"\\nMissing Skills\")\n# for s in skill_missing:\n#     print(f\"- {s}\")\n\n# print(\"\\nCV Score\")\n# print(f\"{score}% match\" if score is not None else \"No score found\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## analyze_video","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom deepface import DeepFace\nfrom collections import Counter\n\ndef analyze_video(video_path):\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    frames_samples = 20\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        mean_intensity = gray.mean()\n        if mean_intensity < 10:  \n            continue        \n        frames.append(frame)\n\n    cap.release()\n\n    if len(frames) == 0:\n        return {\"confidence\": 0, \"anxiety\": 0, \"emotions_distribution\": {}, \"frames_sampled\": 0}\n\n    step = max(1, len(frames) // frames_samples)\n    selected_frames = [frames[i] for i in range(0, len(frames), step)][:frames_samples]\n\n    emotions = []\n    for frame in selected_frames:\n        try:\n            result = DeepFace.analyze(frame, actions=[\"emotion\"], enforce_detection=False)\n            if isinstance(result, list):\n                result = result[0]\n            emotions.append(result.get(\"dominant_emotion\", \"unknown\"))\n        except Exception:\n            emotions.append(\"unknown\")\n\n    confidence_emotions = {\"happy\", \"neutral\", \"calm\"}\n    anxiety_emotions = {\"fear\", \"sad\", \"angry\", \"disgust\"}     \n\n    distribution = Counter(emotions)\n\n    confidence_count = sum(distribution[e] for e in confidence_emotions)\n    anxiety_count = sum(distribution[e] for e in anxiety_emotions)\n    total = confidence_count + anxiety_count\n\n    confidence_score = round((confidence_count / total) * 100, 1) if total > 0 else 0.0\n    anxiety_score = round((anxiety_count / total) * 100, 1) if total > 0 else 0.0\n\n    return {\n        \"confidence\": confidence_score,   \n        \"anxiety\": anxiety_score,         \n        \"emotions_distribution\": dict(distribution),\n        \"frames_sampled\": len(selected_frames)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:46:20.799995Z","iopub.execute_input":"2025-12-10T11:46:20.800609Z","iopub.status.idle":"2025-12-10T11:46:20.808628Z","shell.execute_reply.started":"2025-12-10T11:46:20.800584Z","shell.execute_reply":"2025-12-10T11:46:20.807843Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# video_path=\"/kaggle/input/test2v/test2.mp4\"\n# result = analyze_video(video_path)\n# print(result)\n# print(result[\"confidence\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:29:58.175953Z","iopub.execute_input":"2025-12-10T11:29:58.176468Z","iopub.status.idle":"2025-12-10T11:29:58.188522Z","shell.execute_reply.started":"2025-12-10T11:29:58.176444Z","shell.execute_reply":"2025-12-10T11:29:58.187950Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# video_path=\"/kaggle/input/test2v/test2.mp4\"\n# result = analyze_video(video_path)\n# print(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:29:58.226122Z","iopub.status.idle":"2025-12-10T11:29:58.226347Z","shell.execute_reply.started":"2025-12-10T11:29:58.226238Z","shell.execute_reply":"2025-12-10T11:29:58.226253Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## generate_verdict","metadata":{}},{"cell_type":"code","source":"import re\n\ndef generate_verdict(cv_score, matched, missing, confidence, anxiety):\n    cv_score = cv_score or 0.0\n    confidence = confidence or 0.0\n    anxiety = anxiety or 0.0\n    matched = matched or []\n    missing = missing or []\n\n    behavior = (\n        \"confident\" if confidence > anxiety else\n        \"anxious\" if anxiety > confidence else\n        \"neutral\"\n    )\n\n    video_score = confidence\n    final_score = round((cv_score * 0.7 + video_score * 0.3), 2)\n\n    if cv_score == 0.0 or not matched:\n        verdict_text = (\n            f\"The candidate has no matching skills in the CV and appears {behavior}. \"\n            \"The candidate is not suitable for the position.\"\n        )\n        return verdict_text, final_score, behavior, video_score\n\n    matched_skills = \", \".join(matched)\n    missing_skills = \", \".join(missing) if missing else \"None\"\n\n    prompt = f\"\"\"\nYou are an expert recruiter.\n\nCandidate Evaluation:\n\n- CV Score: {cv_score}%\n- Video Behavior: {behavior}\n- Matched Skills: {matched_skills}\n- Missing Skills: {missing_skills}\n- Final Score: {final_score}\n\nTask:\n\nWrite a concise HR verdict in EXACTLY TWO sentences. \nSentence 1: Highlight the candidate's strengths and matched skills.\nSentence 2: Mention missing skills and video behavior, then give a clear recommendation.\nDo not add anything else.\n\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        temperature=0.3,\n        top_p=0.9,\n        do_sample=True\n    )\n\n    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    if full_output.startswith(prompt):\n        verdict_text = full_output[len(prompt):].strip()\n    else:\n        verdict_text = full_output.strip()\n\n    sentences = re.split(r'(?<=[.!?])\\s+', verdict_text)\n\n    if len(sentences) >= 2:\n        verdict_text = ' '.join(sentences[:2])\n    elif len(sentences) == 1:\n        verdict_text = sentences[0]\n    else:\n        verdict_text = (\n            f\"The candidate shows {behavior} behavior with CV score {cv_score}%. \"\n            f\"Matched skills: {matched_skills}. Missing skills: {missing_skills}.\"\n        )\n\n    return verdict_text, final_score, behavior, video_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:09:58.674544Z","iopub.execute_input":"2025-12-10T12:09:58.675123Z","iopub.status.idle":"2025-12-10T12:09:58.682679Z","shell.execute_reply.started":"2025-12-10T12:09:58.675097Z","shell.execute_reply":"2025-12-10T12:09:58.681755Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def format_output(cv_score, video_score, final_score, verdict, behavior):\n    text = f\"\"\"Final Score:\n• CV Score (70%): {cv_score}\n• Video Score (30%): {video_score}\n• Candidate behavior: {behavior}\n• Final = {final_score}\n{verdict}\n\"\"\"\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:02:52.502959Z","iopub.execute_input":"2025-12-10T12:02:52.503784Z","iopub.status.idle":"2025-12-10T12:02:52.507402Z","shell.execute_reply.started":"2025-12-10T12:02:52.503759Z","shell.execute_reply":"2025-12-10T12:02:52.506736Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"## FASTAPI APP","metadata":{}},{"cell_type":"code","source":"# !pip install fastapi uvicorn nest_asyncio python-multipart\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:29:58.229591Z","iopub.status.idle":"2025-12-10T11:29:58.229872Z","shell.execute_reply.started":"2025-12-10T11:29:58.229711Z","shell.execute_reply":"2025-12-10T11:29:58.229730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import uvicorn\nfrom fastapi import FastAPI, UploadFile, File, Form\nfrom threading import Thread\nimport uuid\nimport os\nimport requests\nfrom threading import Thread\nimport json\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:46:37.910257Z","iopub.execute_input":"2025-12-10T11:46:37.910814Z","iopub.status.idle":"2025-12-10T11:46:37.945523Z","shell.execute_reply.started":"2025-12-10T11:46:37.910788Z","shell.execute_reply":"2025-12-10T11:46:37.945009Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import nest_asyncio\nnest_asyncio.apply()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:46:41.432930Z","iopub.execute_input":"2025-12-10T11:46:41.433216Z","iopub.status.idle":"2025-12-10T11:46:41.445632Z","shell.execute_reply.started":"2025-12-10T11:46:41.433196Z","shell.execute_reply":"2025-12-10T11:46:41.445038Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"app = FastAPI()\nresults = {}\n\n@app.post(\"/evaluate\")\nasync def evaluate(\n    job_description: str = Form(...),\n    cv_path: str = Form(...),\n    video_path: str = Form(...)\n):\n    session_id = str(uuid.uuid4())\n\n    cv_text = load_file(cv_path)\n    cv_analysis = analyze_cv(cv_text, job_description)\n    cv_score = extract_cv_score(cv_analysis) or 0.0 \n    matched, missing = extract_skills(cv_analysis)\n    \n    video_result = analyze_video(video_path)\n    confidence = video_result.get(\"confidence\", 0.0) \n    anxiety = video_result.get(\"anxiety\", 0.0)\n    \n    verdict, final_score, behavior, video_score = generate_verdict(\n        cv_score, matched, missing, confidence, anxiety\n    )\n\n\n    formatted_output = format_output(cv_score, video_score, final_score, verdict, behavior)\n\n    results[session_id] = {\n        \"cv_text\": cv_text,\n        \"cv_analysis\": cv_analysis,\n        \"cv_score\": cv_score,\n        \"matched_skills\": matched,\n        \"missing_skills\": missing,\n        \"video_result\": video_result,\n        \"behavior\": behavior,\n        \"final_score\": final_score,\n        \"llm_verdict\": verdict,\n        \"formatted_output\": formatted_output  \n    }\n\n    return {\"session_id\": session_id, \"output\": formatted_output}\n\n\n\n@app.get(\"/results\")\nasync def get_results(session_id: str):\n    if session_id not in results:\n        return {\"error\": \"invalid session id\"}\n    return results[session_id]\n\n\ndef run_api():\n  uvicorn.run(app, host=\"0.0.0.0\", port=8007)\n\nthread = Thread(target=run_api, daemon=True)\nthread.start()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:56:49.622374Z","iopub.execute_input":"2025-12-10T11:56:49.622864Z","iopub.status.idle":"2025-12-10T11:56:49.636154Z","shell.execute_reply.started":"2025-12-10T11:56:49.622838Z","shell.execute_reply":"2025-12-10T11:56:49.635109Z"}},"outputs":[{"name":"stderr","text":"INFO:     Started server process [1446]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:8007 (Press CTRL+C to quit)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"jd=\"\"\"To support all aspects of human resources functions within the company, including recruitment, training and development, performance management, and ensuring compliance with company policies and procedures to maintain an effective and organized work environment.\n\nKey Responsibilities:\n\nManage recruitment processes: posting job openings, screening resumes, conducting interviews, and selecting candidates.\n\nCoordinate employee training and development programs.\n\nMonitor performance evaluations and contribute to employee development plans.\n\nImplement company policies and procedures and ensure compliance.\n\nMaintain and update employee records.\n\nHandle employee-related matters such as leave, attendance, and benefits.\n\nProvide support and guidance to employees regarding internal policies and company regulations.\n\nPrepare HR reports and statistics as needed.\n\nQualifications:\n\nBachelor’s degree in Business Administration, Human Resources, or related field.\n\n1–3 years of experience in Human Resources (depending on level).\n\nGood knowledge of labor laws and local regulations.\n\nStrong communication and organizational skills.\n\nAbility to handle sensitive information with confidentiality.\n\nProficiency in computer applications and HR software.\n\nPersonal Skills:\n\nProblem-solving and decision-making abilities.\n\nNegotiation and persuasion skills.\n\nAbility to work collaboratively in a team environment.\n\n\n\"\"\"\n\nresp = requests.post(\n    \"http://127.0.0.1:8007/evaluate\",\n    data={\n        \"job_description\": jd,\n        \"cv_path\": \"/kaggle/input/cv-version4/Nagwa Mohamed-Data Scientist II.pdf\",\n        \"video_path\": \"/kaggle/input/video1/test1.webm\"\n    }\n)\n\ndata = resp.json()  \nprint(data[\"output\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:10:06.280196Z","iopub.execute_input":"2025-12-10T12:10:06.281035Z","iopub.status.idle":"2025-12-10T12:11:30.389805Z","shell.execute_reply.started":"2025-12-10T12:10:06.281004Z","shell.execute_reply":"2025-12-10T12:11:30.389113Z"}},"outputs":[{"name":"stderr","text":"Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.89it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.17it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.97it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.37it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 17.65it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.11it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.68it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.39it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.30it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.25it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.16it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.56it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.17it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.96it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.14it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.10it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.70it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.68it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.31it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.19it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.16it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.99it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 17.62it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.26it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.56it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 20.01it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.95it/s]","output_type":"stream"},{"name":"stdout","text":"INFO:     127.0.0.1:32944 - \"POST /evaluate HTTP/1.1\" 200 OK\nFinal Score:\n• CV Score (70%): 0.0\n• Video Score (30%): 75.0\n• Candidate behavior: confident\n• Final = 22.5\nThe candidate has no matching skills in the CV and appears confident. The candidate is not suitable for the position.\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"# Dash App","metadata":{}},{"cell_type":"code","source":"from pyngrok import ngrok, conf\nconf.get_default().auth_token = \"36F0BxzfgoiXChAeN7oJ4MflnlF_2AjXn8jbAnkxHQh8WLAiT\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T11:58:38.699516Z","iopub.execute_input":"2025-12-10T11:58:38.699813Z","iopub.status.idle":"2025-12-10T11:58:38.703836Z","shell.execute_reply.started":"2025-12-10T11:58:38.699794Z","shell.execute_reply":"2025-12-10T11:58:38.703048Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"import dash\nfrom dash import html, dcc, Input, Output, State\nimport dash_bootstrap_components as dbc\nimport base64\n\napp = dash.Dash(\n    __name__,\n    external_stylesheets=[dbc.themes.BOOTSTRAP],\n    suppress_callback_exceptions=True\n)\n\n# LAYOUT\napp.layout = html.Div(\n    style={\"padding\": \"30px\", \"backgroundColor\": \"#f5f7fa\"},\n    children=[\n\n        html.Div(\n            style={\"display\": \"flex\", \"gap\": \"30px\", \"marginTop\": \"20px\"},\n            children=[\n\n                # LEFT SIDE (UPLOADS)\n                html.Div(\n                    style={\"width\": \"48%\", \"background\": \"white\",\n                           \"padding\": \"20px\", \"borderRadius\": \"10px\"},\n                    children=[\n\n                        html.H4(\"Upload CV\"),\n                        dcc.Upload(\n                            id=\"upload-cv\",\n                            children=html.Div(\n                                id=\"cv-upload-text\",\n                                children=[\"Drag & Drop or Select CV File\"]\n                            ),\n                            style={\n                                \"height\": \"120px\",\n                                \"border\": \"2px dashed #007bff\",\n                                \"borderRadius\": \"10px\",\n                                \"textAlign\": \"center\",\n                                \"paddingTop\": \"40px\",\n                                \"color\": \"#007bff\"\n                            }\n                        ),\n                        html.Div(id=\"cv_upload_status\", style={\"marginTop\": \"10px\"}),\n\n                        html.H4(\"Upload Video\", style={\"marginTop\": \"30px\"}),\n                        dcc.Upload(\n                            id=\"upload-video\",\n                            children=html.Div(\n                                id=\"video-upload-text\",\n                                children=[\"Drag & Drop or Select Video File\"]\n                            ),\n                            style={\n                                \"height\": \"120px\",\n                                \"border\": \"2px dashed #28a745\",\n                                \"borderRadius\": \"10px\",\n                                \"textAlign\": \"center\",\n                                \"paddingTop\": \"40px\",\n                                \"color\": \"#28a745\"\n                            }\n                        ),\n                        html.Div(id=\"video_upload_status\", style={\"marginTop\": \"10px\"}),\n                    ]\n                ),\n\n                # RIGHT SIDE (JD)\n                html.Div(\n                    style={\"width\": \"48%\", \"background\": \"white\",\n                           \"padding\": \"20px\", \"borderRadius\": \"10px\"},\n                    children=[\n                        html.H4(\"Job Description\"),\n                        dcc.Textarea(\n                            id=\"jd-text\",\n                            placeholder=\"Paste Job Description here...\",\n                            style={\"width\": \"100%\", \"height\": \"300px\",\n                                   \"borderRadius\": \"10px\",\n                                   \"padding\": \"10px\",\n                                   \"border\": \"1px solid #ccc\"}\n                        ),\n                    ]\n                )\n            ]\n        ),\n\n        # RESULTS\n        html.Div(\n            style={\"background\": \"white\", \"padding\": \"20px\",\n                   \"marginTop\": \"30px\", \"borderRadius\": \"10px\"},\n            children=[\n\n                html.Div(style={\"textAlign\": \"center\"}, children=[\n                    html.Button(\n                        \"Evaluate Candidate\",\n                        id=\"eval-btn\",\n                        n_clicks=0,\n                        style={\n                            \"background\": \"#007bff\",\n                            \"color\": \"white\",\n                            \"padding\": \"14px 20px\",\n                            \"borderRadius\": \"8px\",\n                            \"fontSize\": \"25px\",\n                            \"cursor\": \"pointer\"\n                        }\n                    )\n                ]),\n\n                dcc.Loading(\n                    id=\"loading_wrapper\",\n                    type=\"circle\",\n                    color=\"#003366\",\n                    children=html.Div(\n                        id=\"results-output\",\n                        style={\n                            \"whiteSpace\": \"pre-wrap\",\n                            \"minHeight\": \"150px\",\n                            \"marginTop\": \"20px\",\n                            \"fontSize\": \"17px\"\n                        }\n                    )\n                )\n            ]\n        )\n    ]\n)\n\n#CV UPLOAD STATUS CALLBACK\n@app.callback(\n    Output(\"cv-upload-text\", \"children\"),\n    Input(\"upload-cv\", \"contents\"),\n    State(\"upload-cv\", \"filename\"),\n)\ndef update_cv_status(content, filename):\n    if content:\n        return f\"Uploaded: {filename}\"\n    return \"Drag & Drop or Select CV File\"\n\n# VIDEO UPLOAD STATUS CALLBACK\n@app.callback(\n    Output(\"video-upload-text\", \"children\"),\n    Input(\"upload-video\", \"contents\"),\n    State(\"upload-video\", \"filename\"),\n)\ndef update_video_status(content, filename):\n    if content:\n        return f\"Uploaded: {filename}\"\n    return \"Drag & Drop or Select Video File\"\n\n\n#MAIN EVALUATION CALLBACK\n@app.callback(\n    Output(\"results-output\", \"children\"),\n    Input(\"eval-btn\", \"n_clicks\"),\n    State(\"upload-cv\", \"contents\"),\n    State(\"upload-cv\", \"filename\"),\n    State(\"upload-video\", \"contents\"),\n    State(\"upload-video\", \"filename\"),\n    State(\"jd-text\", \"value\"),\n)\ndef evaluate(n_clicks, cv_content, cv_name, video_content, video_name, jd_text):\n\n    if not n_clicks:\n        return \"\"\n\n    if not (cv_content and video_content and jd_text):\n        return \"Please upload CV, Video, and paste JD.\"\n\n    # SAVE CV \n    cv_data = cv_content.split(\",\")[1]\n    cv_bytes = base64.b64decode(cv_data)\n\n    cv_path = f\"/tmp/{cv_name}\"\n    with open(cv_path, \"wb\") as f:\n        f.write(cv_bytes)\n\n    cv_text = load_file(cv_path)\n    result= analyze_cv(cv_text, jd_text)\n    cv_score = extract_cv_score(result)\n    matched, missing = extract_skills(result)\n\n\n    #SAVE VIDEO \n    video_data = video_content.split(\",\")[1]\n    video_bytes = base64.b64decode(video_data)\n\n    video_path = f\"/tmp/{video_name}\"\n    with open(video_path, \"wb\") as f:\n        f.write(video_bytes)\n\n    video_result = analyze_video(video_path)\n    confidence = video_result.get(\"confidence\", 0.0)\n    anxiety = video_result.get(\"anxiety\", 0.0)\n\n    verdict, final_score, behavior, video_score = generate_verdict(\n    cv_score, matched, missing, confidence, anxiety  )\n                                \n\n    result_text = format_output(cv_score, video_score, final_score, verdict, behavior)\n\n    return html.Pre(result_text, style={\"whiteSpace\": \"pre-wrap\", \"fontSize\": \"25px\"})\n\n\nif __name__ == \"__main__\":\n    from pyngrok import ngrok\n    ngrok.kill()\n    public_url = ngrok.connect(8050)\n    print(\"Dash app running at:\", public_url)\n    app.run(host=\"0.0.0.0\", port=8050)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T12:12:15.265713Z","iopub.execute_input":"2025-12-10T12:12:15.266057Z","iopub.status.idle":"2025-12-10T12:12:15.690737Z","shell.execute_reply.started":"2025-12-10T12:12:15.266026Z","shell.execute_reply":"2025-12-10T12:12:15.690170Z"}},"outputs":[{"name":"stdout","text":"Dash app running at: NgrokTunnel: \"https://d1530df9079f.ngrok-free.app\" -> \"http://localhost:8050\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.lib.display.IFrame at 0x7d047825d610>","text/html":"\n        <iframe\n            width=\"100%\"\n            height=\"650\"\n            src=\"http://0.0.0.0:8050/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "},"metadata":{}},{"name":"stderr","text":"Action: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.13it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.51it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.32it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.05it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.47it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.28it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.00it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.38it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.96it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 17.36it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.55it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 17.42it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.02it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.22it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.09it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.11it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.54it/s]\nAction: emotion: 100%|██████████| 1/1 [00:00<00:00, 18.90it/s]\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"}],"execution_count":55}]}