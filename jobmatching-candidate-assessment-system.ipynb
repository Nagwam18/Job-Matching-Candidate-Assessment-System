{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13879561,"sourceType":"datasetVersion","datasetId":8842878},{"sourceId":13879935,"sourceType":"datasetVersion","datasetId":8843112},{"sourceId":13912823,"sourceType":"datasetVersion","datasetId":8864990},{"sourceId":13913555,"sourceType":"datasetVersion","datasetId":8865490}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation","metadata":{}},{"cell_type":"code","source":"# !pip install fastapi starlette pdfplumber pytesseract docx2txt Pillow opencv-python deepface google-generativeai\n# !sudo apt-get install -y tesseract-ocr\n\n# !pip install --upgrade numpy==1.26.4 scipy==1.12.0\n# !pip install --upgrade tensorflow==2.15.0 keras==2.15.0\n\n# !pip install --force-reinstall deepface\n\n# !sudo apt-get purge python3-scipy\n\n\n# !pip install pyngrok\n\n# !pip install dash dash-bootstrap-components\n# !pip install plotly\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:46.513487Z","iopub.execute_input":"2025-12-02T21:48:46.514259Z","iopub.status.idle":"2025-12-02T21:48:46.518213Z","shell.execute_reply.started":"2025-12-02T21:48:46.514231Z","shell.execute_reply":"2025-12-02T21:48:46.517324Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport io\nimport re\nimport uuid\nimport json\nimport tempfile\n\nfrom fastapi import FastAPI, UploadFile, File, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom starlette.responses import JSONResponse\n\nimport pdfplumber\nimport pytesseract\nimport docx2txt\nimport re\nfrom PIL import Image\n\nimport cv2\nfrom deepface import DeepFace\n\nimport google.generativeai as genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T22:13:05.738716Z","iopub.execute_input":"2025-12-02T22:13:05.739526Z","iopub.status.idle":"2025-12-02T22:13:05.744291Z","shell.execute_reply.started":"2025-12-02T22:13:05.739499Z","shell.execute_reply":"2025-12-02T22:13:05.743434Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# api_key = \"AIzaSyBDHBQbjUajMonEQKjBc9lbovDNIt5q_uM\"\n# genai.configure(api_key=api_key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:54.736484Z","iopub.execute_input":"2025-12-02T21:48:54.737062Z","iopub.status.idle":"2025-12-02T21:48:54.741043Z","shell.execute_reply.started":"2025-12-02T21:48:54.737040Z","shell.execute_reply":"2025-12-02T21:48:54.740342Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"markdown","source":"## load_file","metadata":{}},{"cell_type":"code","source":"def load_file(path):\n    ext = os.path.splitext(path)[1].lower()\n    if ext==\".pdf\":\n        text=\"\"\n        with pdfplumber.open(path) as pdf:\n            for p in pdf.pages:\n                t = p.extract_text()\n                if t: text+=t+\"\\n\"\n        if text.strip():\n            return text\n    \n        ocr=\"\"\n        with pdfplumber.open(path) as pdf:\n            for p in pdf.pages:\n                img=p.to_image(resolution=300).original\n                ocr+=pytesseract.image_to_string(img)\n        return ocr\n    if ext==\".docx\":\n        return docx2txt.process(path) or \"\"\n    if ext==\".txt\":\n        return open(path,\"r\",encoding=\"utf-8\", errors=\"ignore\").read()\n    if ext in [\".jpg\",\".jpeg\",\".png\"]:\n        return pytesseract.image_to_string(Image.open(path))\n    return \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:54.741754Z","iopub.execute_input":"2025-12-02T21:48:54.742033Z","iopub.status.idle":"2025-12-02T21:48:54.758033Z","shell.execute_reply.started":"2025-12-02T21:48:54.742009Z","shell.execute_reply":"2025-12-02T21:48:54.757240Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## analyze_cv","metadata":{}},{"cell_type":"code","source":"def analyze_cv(cv_text, jd_text):\n    prompt = f\"\"\"\nYou are an expert recruiter.\nYou can analyze CVs and Job Descriptions from any domain (technical, business, healthcare, education, customer service, etc.).\nCV:\n{cv_text}\n\nJob Description:\n{jd_text}\n\nTasks:\n1. Extract skills , education and experience from CV and Job Description.\n2. Perform semantic matching (synonyms, related tools, transferable skills).\n3. Apply weighted scoring:\n   - Skills: 40%\n   - Work Experience: 30%\n   - Education: 20%\n   - Certifications/Projects: if explicitly required in JD.\n\nReturn the result strictly in this format:\n\nMatched Skills\n- skill1\n- skill2\n...\n\nMissing Skills\n- skill1\n- skill2\n...\n\nCV Score\nXX.X% match\n\nRules:\n- Do not acknowledge instructions.\n- Do not explain.\n- Only output the result in the exact format above.\n\"\"\"\n    api_key = \"AIzaSyBDHBQbjUajMonEQKjBc9lbovDNIt5q_uM\"\n    genai.configure(api_key=api_key)\n    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n    response = model.generate_content(\n        prompt,\n        generation_config={\n            \"temperature\": 0,\n            \"top_p\": 1,\n            \"top_k\": 1,\n            \"candidate_count\": 1\n        }\n    )\n    return response.candidates[0].content.parts[0].text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:54.758854Z","iopub.execute_input":"2025-12-02T21:48:54.759217Z","iopub.status.idle":"2025-12-02T21:48:54.777975Z","shell.execute_reply.started":"2025-12-02T21:48:54.759189Z","shell.execute_reply":"2025-12-02T21:48:54.777339Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## extract_cv score&skills","metadata":{}},{"cell_type":"code","source":"def extract_cv_score(result_text):\n    match = re.search(r\"CV Score\\s*([\\d.]+)%\", result_text, re.IGNORECASE)\n    if match:\n        score_percent = float(match.group(1))     \n        return score_percent / 100               \n    else:\n        return None\n        \ndef extract_skills(result_text):\n    matched = []\n    missing = []\n\n    lines = result_text.splitlines()\n    mode = None\n\n    for line in lines:\n        line = line.strip()\n\n        if line.lower().startswith(\"matched skills\"):\n            mode = \"matched\"\n            continue\n        elif line.lower().startswith(\"missing skills\"):\n            mode = \"missing\"\n            continue\n        elif line.lower().startswith(\"cv score\"):\n            mode = None\n            continue\n\n        if mode == \"matched\" and line.startswith(\"-\"):\n            matched.append(line[1:].strip())\n        elif mode == \"missing\" and line.startswith(\"-\"):\n            missing.append(line[1:].strip())\n\n    return matched, missing\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:54.778798Z","iopub.execute_input":"2025-12-02T21:48:54.779032Z","iopub.status.idle":"2025-12-02T21:48:54.795222Z","shell.execute_reply.started":"2025-12-02T21:48:54.779016Z","shell.execute_reply":"2025-12-02T21:48:54.794548Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## analyze_video","metadata":{}},{"cell_type":"code","source":"def analyze_video(video_path):\n    import cv2\n    from deepface import DeepFace\n    import json\n    import google.generativeai as genai\n\n    api_key = \"AIzaSyBDHBQbjUajMonEQKjBc9lbovDNIt5q_uM\"\n    genai.configure(api_key=api_key)\n    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n\n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    frames_samples = 20\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frames.append(frame)\n    cap.release()\n\n    if len(frames) == 0:\n        return {\"confidence\": 0, \"anxiety\": 0, \"emotions\": [], \"frames_sampled\": 0}\n\n    step = max(1, len(frames) // frames_samples)\n    selected_frames = [frames[i] for i in range(0, len(frames), step)][:frames_samples]\n\n    emotions = []\n    for frame in selected_frames:\n        try:\n            result = DeepFace.analyze(frame, actions=[\"emotion\"], enforce_detection=False)\n            if isinstance(result, list):\n                result = result[0]\n            emotions.append(result.get(\"dominant_emotion\", \"unknown\"))\n        except Exception:\n            emotions.append(\"unknown\")\n\n    # ========= Prompt مضبوط =========\n    prompt = f\"\"\"\nYou are an expert in behavioral psychology and interview analysis.\n\nEmotions detected from candidate video: {emotions}\n\nTasks:\n1. Estimate overall confidence (0 to 1).\n2. Estimate overall anxiety (0 to 1).\n\nRules:\n- Confidence increases with: happy, neutral, calm\n- Anxiety increases with: fear, sad, angry, disgust\n- Return ONLY a valid JSON object, no text, no explanation.\n\nExample:\n{{\"confidence\": 0.72, \"anxiety\": 0.28}}\n\"\"\"\n\n    response = model.generate_content(prompt)\n    raw_text = getattr(response, \"text\", \"\").strip()\n    match = re.search(r\"\\{.*\\}\", raw_text, re.DOTALL)\n    if match:\n        raw_text = match.group(0)\n\n    try:\n        data = json.loads(raw_text)\n        confidence = float(data.get(\"confidence\", 0.0))\n        anxiety = float(data.get(\"anxiety\", 0.0))\n    except Exception:\n        confidence, anxiety = 0.0, 0.0\n\n    return {\n        \"confidence\": confidence,\n        \"anxiety\": anxiety,\n        \"emotions\": emotions,\n        \"frames_sampled\": len(selected_frames),\n        \"llm_raw\": raw_text\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:54.795936Z","iopub.execute_input":"2025-12-02T21:48:54.796206Z","iopub.status.idle":"2025-12-02T21:48:54.814010Z","shell.execute_reply.started":"2025-12-02T21:48:54.796176Z","shell.execute_reply":"2025-12-02T21:48:54.813256Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# video_path=\"/kaggle/input/video1/test1.webm\"\n# result = analyze_video(video_path)\n# print(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:54.814865Z","iopub.execute_input":"2025-12-02T21:48:54.815089Z","iopub.status.idle":"2025-12-02T21:48:54.831538Z","shell.execute_reply.started":"2025-12-02T21:48:54.815074Z","shell.execute_reply":"2025-12-02T21:48:54.830893Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## generate_verdict","metadata":{}},{"cell_type":"code","source":"def generate_verdict(cv_score, matched, missing, confidence, anxiety):\n    behavior = (\n        \"confident\" if confidence > anxiety else\n        \"anxious\" if anxiety > confidence else\n        \"neutral\"\n    )\n\n    final_score = round((cv_score * 0.7 + max(confidence, anxiety) * 0.3), 2)\n\n    matched_skills = \", \".join(matched)\n    missing_skills = \", \".join(missing)\n\n    prompt = f\"\"\"\nYou are an expert recruiter.\n\nCandidate Evaluation:\n\nCV Score: {cv_score}\nVideo Behavior: {behavior}\nMatched Skills: {matched_skills}\nMissing Skills: {missing_skills}\nFinal Score: {final_score}\n\nWrite a concise, professional verdict for HR.\nGuidelines:\n- Maximum 2 sentences.\n- Highlight strengths clearly.\n- Mention missing skills briefly.\n- Explicitly state video behavior (e.g., \"Candidate is confident\", \"Candidate appeared anxious\").\n- End with a clear recommendation (e.g., \"worth considering\", \"needs development\").\n- Return exactly this format:\nllm_verdict:\n<sentence1>\n<sentence2>\n\"\"\"\n    api_key = \"AIzaSyBDHBQbjUajMonEQKjBc9lbovDNIt5q_uM\"\n    genai.configure(api_key=api_key)\n    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n    response = model.generate_content(prompt)\n    verdict = response.text.strip()\n\n    return verdict, final_score ,behavior\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T22:06:07.656223Z","iopub.execute_input":"2025-12-02T22:06:07.656559Z","iopub.status.idle":"2025-12-02T22:06:07.662695Z","shell.execute_reply.started":"2025-12-02T22:06:07.656540Z","shell.execute_reply":"2025-12-02T22:06:07.661761Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def format_output(cv_score, video_score, final_score, verdict,behavior):\n    text = f\"\"\"Final Score:\n• CV Match (70%): {cv_score}\n• Video Score (30%): {video_score}\n• Candidate behavior: {behavior}\n• Final = {final_score}\n• {verdict}\n\"\"\"\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T22:10:53.183883Z","iopub.execute_input":"2025-12-02T22:10:53.184501Z","iopub.status.idle":"2025-12-02T22:10:53.188645Z","shell.execute_reply.started":"2025-12-02T22:10:53.184478Z","shell.execute_reply":"2025-12-02T22:10:53.187894Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"# Dash App","metadata":{}},{"cell_type":"code","source":"from pyngrok import ngrok, conf\nconf.get_default().auth_token = \"36F0BxzfgoiXChAeN7oJ4MflnlF_2AjXn8jbAnkxHQh8WLAiT\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T21:48:54.862316Z","iopub.execute_input":"2025-12-02T21:48:54.862628Z","iopub.status.idle":"2025-12-02T21:48:54.875411Z","shell.execute_reply.started":"2025-12-02T21:48:54.862611Z","shell.execute_reply":"2025-12-02T21:48:54.874768Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import dash\nfrom dash import html, dcc, Input, Output, State\nimport dash_bootstrap_components as dbc\nimport base64\n\napp = dash.Dash(\n    __name__,\n    external_stylesheets=[dbc.themes.BOOTSTRAP],\n    suppress_callback_exceptions=True\n)\n\n# LAYOUT\napp.layout = html.Div(\n    style={\"padding\": \"30px\", \"backgroundColor\": \"#f5f7fa\"},\n    children=[\n\n        html.Div(\n            style={\"display\": \"flex\", \"gap\": \"30px\", \"marginTop\": \"20px\"},\n            children=[\n\n                # LEFT SIDE (UPLOADS)\n                html.Div(\n                    style={\"width\": \"48%\", \"background\": \"white\",\n                           \"padding\": \"20px\", \"borderRadius\": \"10px\"},\n                    children=[\n\n                        html.H4(\"Upload CV\"),\n                        dcc.Upload(\n                            id=\"upload-cv\",\n                            children=html.Div(\n                                id=\"cv-upload-text\",\n                                children=[\"Drag & Drop or Select CV File\"]\n                            ),\n                            style={\n                                \"height\": \"120px\",\n                                \"border\": \"2px dashed #007bff\",\n                                \"borderRadius\": \"10px\",\n                                \"textAlign\": \"center\",\n                                \"paddingTop\": \"40px\",\n                                \"color\": \"#007bff\"\n                            }\n                        ),\n                        html.Div(id=\"cv_upload_status\", style={\"marginTop\": \"10px\"}),\n\n                        html.H4(\"Upload Video\", style={\"marginTop\": \"30px\"}),\n                        dcc.Upload(\n                            id=\"upload-video\",\n                            children=html.Div(\n                                id=\"video-upload-text\",\n                                children=[\"Drag & Drop or Select Video File\"]\n                            ),\n                            style={\n                                \"height\": \"120px\",\n                                \"border\": \"2px dashed #28a745\",\n                                \"borderRadius\": \"10px\",\n                                \"textAlign\": \"center\",\n                                \"paddingTop\": \"40px\",\n                                \"color\": \"#28a745\"\n                            }\n                        ),\n                        html.Div(id=\"video_upload_status\", style={\"marginTop\": \"10px\"}),\n                    ]\n                ),\n\n                # RIGHT SIDE (JD)\n                html.Div(\n                    style={\"width\": \"48%\", \"background\": \"white\",\n                           \"padding\": \"20px\", \"borderRadius\": \"10px\"},\n                    children=[\n                        html.H4(\"Job Description\"),\n                        dcc.Textarea(\n                            id=\"jd-text\",\n                            placeholder=\"Paste Job Description here...\",\n                            style={\"width\": \"100%\", \"height\": \"300px\",\n                                   \"borderRadius\": \"10px\",\n                                   \"padding\": \"10px\",\n                                   \"border\": \"1px solid #ccc\"}\n                        ),\n                    ]\n                )\n            ]\n        ),\n\n        # RESULTS\n        html.Div(\n            style={\"background\": \"white\", \"padding\": \"20px\",\n                   \"marginTop\": \"30px\", \"borderRadius\": \"10px\"},\n            children=[\n\n                html.Div(style={\"textAlign\": \"center\"}, children=[\n                    html.Button(\n                        \"Evaluate Candidate\",\n                        id=\"eval-btn\",\n                        n_clicks=0,\n                        style={\n                            \"background\": \"#007bff\",\n                            \"color\": \"white\",\n                            \"padding\": \"14px 20px\",\n                            \"borderRadius\": \"8px\",\n                            \"fontSize\": \"25px\",\n                            \"cursor\": \"pointer\"\n                        }\n                    )\n                ]),\n\n                dcc.Loading(\n                    id=\"loading_wrapper\",\n                    type=\"circle\",\n                    color=\"#003366\",\n                    children=html.Div(\n                        id=\"results-output\",\n                        style={\n                            \"whiteSpace\": \"pre-wrap\",\n                            \"minHeight\": \"150px\",\n                            \"marginTop\": \"20px\",\n                            \"fontSize\": \"17px\"\n                        }\n                    )\n                )\n            ]\n        )\n    ]\n)\n\n#CV UPLOAD STATUS CALLBACK\n@app.callback(\n    Output(\"cv-upload-text\", \"children\"),\n    Input(\"upload-cv\", \"contents\"),\n    State(\"upload-cv\", \"filename\"),\n)\ndef update_cv_status(content, filename):\n    if content:\n        return f\"Uploaded: {filename}\"\n    return \"Drag & Drop or Select CV File\"\n\n# VIDEO UPLOAD STATUS CALLBACK\n@app.callback(\n    Output(\"video-upload-text\", \"children\"),\n    Input(\"upload-video\", \"contents\"),\n    State(\"upload-video\", \"filename\"),\n)\ndef update_video_status(content, filename):\n    if content:\n        return f\"Uploaded: {filename}\"\n    return \"Drag & Drop or Select Video File\"\n\n\n#MAIN EVALUATION CALLBACK\n@app.callback(\n    Output(\"results-output\", \"children\"),\n    Input(\"eval-btn\", \"n_clicks\"),\n    State(\"upload-cv\", \"contents\"),\n    State(\"upload-cv\", \"filename\"),\n    State(\"upload-video\", \"contents\"),\n    State(\"upload-video\", \"filename\"),\n    State(\"jd-text\", \"value\"),\n)\ndef evaluate(n_clicks, cv_content, cv_name, video_content, video_name, jd_text):\n\n    if not n_clicks:\n        return \"\"\n\n    if not (cv_content and video_content and jd_text):\n        return \"⚠ Please upload CV, Video, and paste JD.\"\n\n    # ---------------- SAVE CV ----------------\n    cv_data = cv_content.split(\",\")[1]\n    cv_bytes = base64.b64decode(cv_data)\n\n    cv_path = f\"/tmp/{cv_name}\"\n    with open(cv_path, \"wb\") as f:\n        f.write(cv_bytes)\n\n    cv_text = load_file(cv_path)\n    result= analyze_cv(cv_text, jd_text)\n    cv_score = extract_cv_score(result)\n    matched, missing = extract_skills(result)\n\n\n    # ---------------- SAVE VIDEO ----------------\n    video_data = video_content.split(\",\")[1]\n    video_bytes = base64.b64decode(video_data)\n\n    video_path = f\"/tmp/{video_name}\"\n    with open(video_path, \"wb\") as f:\n        f.write(video_bytes)\n\n    video_result = analyze_video(video_path)\n    confidence = video_result.get(\"confidence\", 0.0)\n    anxiety = video_result.get(\"anxiety\", 0.0)\n\n    # ---------------- VERDICT ----------------\n    verdict, final_score,behavior = generate_verdict(\n        cv_score, matched, missing, confidence, anxiety\n    )\n\n    # ---------------- OUTPUT ----------------\n    result_text = format_output(cv_score, max(confidence, anxiety), final_score, verdict,behavior)\n    return html.Pre(result_text, style={\"whiteSpace\": \"pre-wrap\", \"fontSize\": \"25px\"})\n\n\nif __name__ == \"__main__\":\n    from pyngrok import ngrok\n    ngrok.kill()\n    public_url = ngrok.connect(8050)\n    print(\"Dash app running at:\", public_url)\n    app.run(host=\"0.0.0.0\", port=8050)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T22:13:36.275557Z","iopub.execute_input":"2025-12-02T22:13:36.275821Z","iopub.status.idle":"2025-12-02T22:13:36.643433Z","shell.execute_reply.started":"2025-12-02T22:13:36.275805Z","shell.execute_reply":"2025-12-02T22:13:36.642819Z"}},"outputs":[{"name":"stdout","text":"Dash app running at: NgrokTunnel: \"https://8b4ae6f6f691.ngrok-free.app\" -> \"http://localhost:8050\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.lib.display.IFrame at 0x7b0961f9ce10>","text/html":"\n        <iframe\n            width=\"100%\"\n            height=\"650\"\n            src=\"http://0.0.0.0:8050/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "},"metadata":{}}],"execution_count":49}]}